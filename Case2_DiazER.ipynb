{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEAM 10: Eliecer Diaz\n",
    "\n",
    "AIM: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of validated Chest X-Ray images described and analyzed in \"Deep learning-based classification and referral of treatable human diseases\".\n",
    "The data was split into three subsets: - 60 % train - 20 % validation - 20 % test\n",
    "Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), “Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification”, Mendeley Data, v2\n",
    "Version 2, published 2018-01-06 University of California San Diego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import collections\n",
    "random.seed(7)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import SensitivityAtSpecificity\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import tensorflow.keras.backend as k\n",
    "import tensorflow.keras.callbacks as Callback\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print(\"Found GPU at: {}\".format(device_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'/kaggle/input/pneumonia/pneumonia2/train'\n",
    "val_dir = r'/kaggle/input/pneumonia/pneumonia2/validation'\n",
    "test_dir = r'/kaggle/input/pneumonia/pneumonia2/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NORMAL', 'PNEUMONIA']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1171 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        #verbose = 0,\n",
    "        shuffle=False,\n",
    "        target_size = (150, 150),\n",
    "        batch_size = 1, #<----tensorflow documentation\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_(SS, batch): # SS: number neurons in the last dense layer, batch: batch size \n",
    "    \n",
    "    #getting new metrics to calculate F1 at the end of the notebook\n",
    "    Preci = tf.keras.metrics.Precision() \n",
    "    Recal = tf.keras.metrics.Recall() \n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                       rotation_range = 5, \n",
    "                                       horizontal_flip = True)\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        #verbose = 0,\n",
    "        target_size = (150, 150),\n",
    "        batch_size = batch,\n",
    "        class_mode = 'binary')\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        #verbose = 0,\n",
    "        target_size = (150, 150),\n",
    "        batch_size = batch,\n",
    "        class_mode='binary')\n",
    "    \n",
    "    try:\n",
    "        with tf.device('/device:GPU:0'):\n",
    "        #with strategy.scope():\n",
    "            model = tf.keras.models.Sequential()\n",
    "            model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "            model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "            model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "            model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "            model.add(tf.keras.layers.Flatten())\n",
    "            model.add(Dense(SS, activation = 'relu'))\n",
    "            model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "            model.compile(loss = 'binary_crossentropy',\n",
    "                          optimizer = tf.keras.optimizers.RMSprop(lr = 1e-4),\n",
    "                          metrics = ['acc', Preci, Recal])\n",
    "            print(\"GPU/TPU IS ON\")\n",
    "    except:\n",
    "        \n",
    "            model = tf.keras.models.Sequential()\n",
    "            model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "            model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "            model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "            model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "            model.add(tf.keras.layers.Flatten())\n",
    "            model.add(Dense(SS, activation = 'relu'))\n",
    "            model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "            model.compile(loss = 'binary_crossentropy',\n",
    "                          optimizer = tf.keras.optimizers.RMSprop(lr = 1e-4),\n",
    "                          metrics = ['acc', Preci, Recal])\n",
    "            print(\"NOT USING GPU\")\n",
    "\n",
    "    return model, train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3513 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "GPU/TPU IS ON\n",
      "Found 3513 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "GPU/TPU IS ON\n",
      "Found 3513 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "GPU/TPU IS ON\n",
      "Found 3513 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "GPU/TPU IS ON\n",
      "Found 3513 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "GPU/TPU IS ON\n",
      "Found 3513 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "GPU/TPU IS ON\n",
      "Found 3513 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "GPU/TPU IS ON\n",
      "Found 3513 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "GPU/TPU IS ON\n",
      "Found 3513 images belonging to 2 classes.\n",
      "Found 1172 images belonging to 2 classes.\n",
      "GPU/TPU IS ON\n"
     ]
    }
   ],
   "source": [
    "SS = [512] # we divide them by 10 after to get: 0.5, 0.7, 0.9\n",
    "batches = [8, 32, 64]\n",
    "models = {}\n",
    "train_generators = {}\n",
    "val_generators = {}\n",
    "\n",
    "for ss in SS:\n",
    "    for batch in batches:\n",
    "        model_ss_batch = 'models_{}_{}'.format(ss, batch)  # creating the keys\n",
    "        models[model_ss_batch] = model_(ss//10, batch) # appending the model to the key\n",
    "        \n",
    "        train_generator_ss_batch = 'train_generators_{}_{}'.format(ss, batch)  # creating the keys\n",
    "        train_generators[train_generator_ss_batch] = model_(ss//10, batch) # appending the generator to the key\n",
    "        \n",
    "        val_generator_ss_batch = 'val_generators_{}_{}'.format(ss, batch)  # creating the keys\n",
    "        val_generators[val_generator_ss_batch] = model_(ss//10, batch) # appending the model to the key       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['models_512_8', 'models_512_32', 'models_512_64'])\n",
      "dict_keys(['train_generators_512_8', 'train_generators_512_32', 'train_generators_512_64'])\n",
      "dict_keys(['val_generators_512_8', 'val_generators_512_32', 'val_generators_512_64'])\n",
      "1171\n"
     ]
    }
   ],
   "source": [
    "print(models.keys()) #prints keys\n",
    "print(train_generators.keys()) #prints keys\n",
    "print(val_generators.keys()) #prints keys\n",
    "\n",
    "print(test_generator.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fd834348f0c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_generators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#1172//batches[i] #None # = 1172 / 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# saving the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Final_models = {}\n",
    "for i in range(len(models)):\n",
    "    print('MODEL:',i)\n",
    "    Final_model_i = 'models_{}'.format(i)  # creating the keys\n",
    "    Final_models[Final_model_i] = models[list(models.keys())[i]][0].fit_generator(\n",
    "        train_generators[list(train_generators.keys())[i]][1],\n",
    "        steps_per_epoch = None, #3513//batches[i],#None, # = 3513 / 8\n",
    "        verbose = 0,\n",
    "        epochs = 100,\n",
    "        validation_data = val_generators[list(val_generators.keys())[i]][1],\n",
    "        validation_steps = None, #1172//batches[i] #None # = 1172 / 8\n",
    "    )\n",
    "    # saving the model\n",
    "    models[list(models.keys())[i]][0].save(\"model{}.h5\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Final_models)):\n",
    "    print(i)\n",
    "    models_key = Final_models.keys()\n",
    "    model_key = [j  for  j in  models_key]\n",
    "    metrics = Final_models[list(Final_models.keys())[i]].history.keys()\n",
    "    metric = [k  for  k in  metrics]\n",
    "    \n",
    "    acc = Final_models[list(Final_models.keys())[i]].history[metric[1]]\n",
    "    val_acc = Final_models[list(Final_models.keys())[i]].history[metric[5]]\n",
    "    \n",
    "    preci = Final_models[list(Final_models.keys())[i]].history[metric[2]]\n",
    "    val_preci = Final_models[list(Final_models.keys())[i]].history[metric[6]]\n",
    "    \n",
    "    recal = Final_models[list(Final_models.keys())[i]].history[metric[3]]\n",
    "    val_recal = Final_models[list(Final_models.keys())[i]].history[metric[7]]\n",
    "    \n",
    "    loss = Final_models[list(Final_models.keys())[i]].history[metric[0]]\n",
    "    val_loss = Final_models[list(Final_models.keys())[i]].history[metric[4]]\n",
    "    \n",
    "    epochs = range(len(acc))\n",
    "        \n",
    "    fig, axs = plt.subplots(1, 4, figsize=(10, 10))\n",
    "    \n",
    "    \n",
    "    axs[ 0].set_title('1. Accuracy')\n",
    "    axs[ 0].plot(epochs, acc, 'bo-', label = 'Training acc')\n",
    "    axs[ 0].plot(epochs, val_acc, 'r*-', label = 'Validation acc')\n",
    "    \n",
    "    axs[ 1].set_title('2. Precision ')\n",
    "    axs[ 1].plot(epochs, preci, 'bo-', label = 'Precision_training ')\n",
    "    axs[ 1].plot(epochs, val_preci, 'r*-', label = 'Precision validation')\n",
    "    \n",
    "    axs[ 2].set_title('3. Recall (sensitivity) ')\n",
    "    axs[ 2].plot(epochs, recal, 'bo-', label = 'Recall training')\n",
    "    axs[ 2].plot(epochs, val_recal, 'r*-', label = 'Recall validation')\n",
    "        \n",
    "    axs[ 3].set_title('4. Loss')\n",
    "    axs[ 3].plot(epochs, loss, 'bo-', label = 'Training loss')\n",
    "    axs[ 3].plot(epochs, val_loss, 'r*-', label = 'Validation loss')\n",
    "    \n",
    "      \n",
    "    fig.suptitle(model_key[i], fontname=\"Times New Roman\",fontweight=\"bold\")\n",
    "    fig.text(0.5, 0.04, 'EPOCH', ha='center', fontname=\"Times New Roman\",fontweight=\"bold\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS? YES...\n",
    "test_generator.reset() # resetting generator\n",
    "for i in range(0,len(Final_models)):\n",
    "    Loss, Accuracy, Preci, Recal = models[list(models.keys())[i]][0].evaluate_generator(generator=val_generators[list(val_generators.keys())[i]][1], steps=10)\n",
    "    print(\"Model\",i)\n",
    "    print('Loss: {}'.format(Loss), 'Accuracy: {}'.format(Accuracy), 'Precision: {}'.format(Preci), 'Recall: {}'.format(Recal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actuall y_labels from test set\n",
    "Y_labels = test_generator.classes\n",
    "\n",
    "# E.g. using model 2, make some predictions with cut-off 0.5\n",
    "for i in range(0,len(Final_models)):\n",
    "    print(\"Prediction for model {}:\".format(i))\n",
    "    \n",
    "    Y_pred = models[list(models.keys())[i]][0].predict_generator(test_generator)\n",
    "    Y_pred = 1*(Y_pred.astype('float64') > 0.5)\n",
    "    \n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(Y_labels, Y_pred))\n",
    "    print('Classification Report')\n",
    "    target_names = ['1','0']\n",
    "    print(classification_report(Y_labels, Y_pred, target_names=target_names))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(Y_labels, Y_pred)\n",
    "#logit_roc_auc_small = roc_auc_score(y_test, model.predict(X_test))\n",
    "#logit_roc_auc_small_reg1 = roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y_labels, Y_pred)\n",
    "#fpr_small, tpr_small, thresholds_small = roc_curve(y_test, model_small.predict_proba(X_test))\n",
    "#fpr_small_reg1, tpr_small_reg1, thresholds_small_reg1 = roc_curve(y_test, model_small_reg1.predict_proba(X_test))\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='MODEL 1 (area = %0.2f)' % logit_roc_auc)\n",
    "#plt.plot(fpr_small, tpr_small, label='MODEL SMALL (area = %0.2f)' % logit_roc_auc_small)\n",
    "#plt.plot(fpr_small_reg1, tpr_small_reg1, label='MODEL SMALL + REGUL2 (area = %0.2f)' % logit_roc_auc_small_reg1)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What for??\n",
    "#sensitivity at specificity? sensitivity \n",
    "Y_labels = Y_labels.reshape(1171,)\n",
    "Y_pred = Y_pred.reshape(1171,)\n",
    "m = tf.keras.metrics.SensitivityAtSpecificity(0.9, num_thresholds = 1)\n",
    "m.update_state(Y_labels, Y_pred)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
