{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import random \nrandom.seed(7)\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models, optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.metrics import SensitivityAtSpecificity\nimport matplotlib.pyplot as plt\nfrom time import time\nimport tensorflow.keras.backend as k\nimport tensorflow.keras.callbacks as Callback\n","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random \nrandom.seed(7)\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.metrics import SensitivityAtSpecificity\nimport matplotlib.pyplot as plt\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simo suggestion:\ntrain_dir = r'/kaggle/input/chest-xray-images-for-classification-pneumonia/train'\nval_dir = r'/kaggle/input/chest-xray-images-for-classification-pneumonia/validation'\ntest_dir = r'/kaggle/input/chest-xray-images-for-classification-pneumonia/test'","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Original directory\n#train_dir='../input/chest-xray-pneumonia/chest_xray/chest_xray/train/'","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir(train_dir)","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"['NORMAL', 'PNEUMONIA']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint(\"Found GPU at: {}\".format(device_name))","execution_count":22,"outputs":[{"output_type":"stream","text":"GPU device not found\nFound GPU at: \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,validation_split=0.3)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_(batch):\n    \n    train_datagen = ImageDataGenerator(rescale=1./255,\n                                       rotation_range = 5, \n                                       horizontal_flip = True)\n    \n    val_datagen = ImageDataGenerator(rescale=1./255)\n\n    train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size = (150, 150),\n        batch_size = batch,\n        class_mode = 'binary')\n    \n    val_generator = val_datagen.flow_from_directory(\n        val_dir,\n        target_size = (150, 150),\n        batch_size = batch,\n        class_mode='binary')\n    \n    try:\n        with tf.device('/gpu:0'):\n            model = tf.keras.models.Sequential()\n            model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(Conv2D(32, (3, 3), activation = 'relu'))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(Conv2D(32, (3, 3), activation = 'relu'))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(Conv2D(32, (3, 3), activation = 'relu'))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(tf.keras.layers.Flatten())\n            model.add(Dense(512, activation = 'relu'))\n            model.add(Dense(1, activation = 'sigmoid'))\n\n            model.compile(loss = 'binary_crossentropy',\n                          optimizer = tf.keras.optimizers.RMSprop(lr = 1e-4),\n                          metrics = [SensitivityAtSpecificity(0.9)])\n    except:\n        \n            model = tf.keras.models.Sequential()\n            model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(Conv2D(32, (3, 3), activation = 'relu'))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(Conv2D(32, (3, 3), activation = 'relu'))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(Conv2D(32, (3, 3), activation = 'relu'))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(tf.keras.layers.Flatten())\n            model.add(Dense(512, activation = 'relu'))\n            model.add(Dense(1, activation = 'sigmoid'))\n\n            model.compile(loss = 'binary_crossentropy',\n                          optimizer = tf.keras.optimizers.RMSprop(lr = 1e-4),\n                          metrics = [SensitivityAtSpecificity(0.9)])\n\n    return model, train_generator, val_generator","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time as time\nstart = time.time()\nhistory_1 = model_8.fit_generator(\n    train_generator,\n    steps_per_epoch = None, # = 3513 / 8\n    verbose = 1,\n    epochs = 10,\n    validation_data = val_generator,\n    validation_steps = None # = 1172 / 8\n)\nend = time.time()\nprint(end-start) #62.2 (2 workers),\n","execution_count":48,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'tuple' object has no attribute 'fit_generator'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-6ba3359da4b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history_1 = model_8.fit_generator(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# = 3513 / 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'fit_generator'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time as time\nstart = time.time()\nhistory_2 = model_1.fit_generator(\n    train_generator_2,\n    steps_per_epoch = 10, # = 3513 / 8\n    verbose = 1,\n    epochs = 10,\n    validation_data = val_generator_1,\n    validation_steps = 10 # = 1172 / 8\n)\nend = time.time()\n\nprint(end-start) #62.2 (2 workers),\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n\n    train_dir,\n    \n    target_size=(150, 150),\n    \n    batch_size=16,\n    \n    class_mode='binary',\n    \n    subset='training')\n    \n     \ndev_generator = train_datagen.flow_from_directory(\n\n            train_dir,\n    \n            target_size=(150, 150),\n    \n            batch_size=16,\n    \n            class_mode='binary',\n    \n            subset='validation')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#here we 70% Training and 30% test which is good!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WE DO NOT NEED THIS CRAP\n#i = 0 \n#for data_batch, labels_batch in train_generator:\n#    print('data batch shape:',data_batch.shape)\n#    print('labels batch shape:',labels_batch.shape)\n#    i = i + 1\n#    if i> 5:\n#        break\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#labels_batch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualize training images**"},{"metadata":{},"cell_type":"markdown","source":"Visualising the training images by extracting a batch of images from the training generator—which is 16 images in this example—then plot five of them with matplotlib."},{"metadata":{"trusted":true},"cell_type":"code","source":"#sample_training_images, _ = next(train_generator) # NOT NEEDED UNLESS WE USE THE TPU!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n#def plotImages(images_arr):\n##    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n#    axes = axes.flatten()\n#    for img, ax in zip( images_arr, axes):\n#        ax.imshow(img)\n#        ax.axis('off')\n#    plt.tight_layout()\n#    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotImages(sample_training_images[:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the model"},{"metadata":{},"cell_type":"markdown","source":"The model consists of three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 512 units on top of it that is activated by a relu activation function. The model outputs class probabilities based on binary classification by the sigmoid activation function."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(32,(3,3), activation ='relu',input_shape = (150,150,3)))\nmodel.add(layers.MaxPool2D(2,2))\nmodel.add(layers.Conv2D(32,(3,3), activation ='relu'))\nmodel.add(layers.MaxPool2D(2,2))\nmodel.add(layers.Conv2D(32,(3,3), activation ='relu'))\nmodel.add(layers.MaxPool2D(2,2))\nmodel.add(layers.Conv2D(32,(3,3), activation ='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation= 'relu'))\nmodel.add(layers.Dense(1,activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compiling the model"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"choosing the RMSprop optimizer and binary cross entropy loss function. To view training and validation accuracy for each training epoch, pass the metrics argument."},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.metrics import  f1_score\nfrom tensorflow.python.keras import optimizers\nPreci = tf.keras.metrics.Precision() \nRecal = tf.keras.metrics.Recall()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Preci, Recal, 'acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nstart = time.time()\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = 10,\n    verbose = 1,\n    epochs = 10, # change epochs: originally 10, 100, 200, 300\n    validation_data = dev_generator,\n    validation_steps = 10,\n    workers = 0, # 0 and 1\n    use_multiprocessing = True)\nend = time.time()\n\nprint(end-start) #62.2 (2 workers),\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"print(history.history.keys()):"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(history.history.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accu = history.history['acc'] #training accuracy\nval_accu = history.history['val_acc'] #validation accuracy\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accu))\n\n# Precision\nPrecision = history.history['precision_1'] #training accuracy\nval_Precision = history.history['val_precision_1'] #validation accuracy\nPrecision_np = np.asarray(Precision, dtype=np.float32)\n\n# Recall\nRecall = history.history['recall_1'] #training accuracy\nval_Recall = history.history['val_recall_1'] #validation accuracy\nRecall_np = np.asarray(Precision, dtype=np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A WELL Tailored F1 score metric\nF1 = 2*(np.divide(np.multiply(Precision_np, Recall_np),np.add(Precision_np, Recall_np)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot(epochs, accu, 'bo-', label = 'Training acc')\nplot(epochs, val_accu, 'r*-', label = 'Validation acc')\nplot(epochs, F1, 'black', label = 'F1')\nlegend()\ngrid()\nshow()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"See the black liine is F1 score!"},{"metadata":{},"cell_type":"markdown","source":"Creating a new network with Dropouts"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_new = models.Sequential([\n    Conv2D(16, 3, padding='same', activation='relu', \n           input_shape=(150, 150 ,3)), #stride =2 default 1 \n    MaxPooling2D(),\n    Dropout(0.2),\n    Conv2D(32, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Dropout(0.2),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(1, activation='sigmoid')\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_new.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel_new.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time()\nhistory = model_new.fit_generator(\n    train_generator,\n    steps_per_epoch = 10,\n    verbose = 0,\n    epochs = 100, # change epochs: originally 10, 100, 200, 300\n    validation_data = dev_generator,\n    validation_steps = 10)\nend = time()\n#save model:\nmodel.save('case2_v2.0.h5') # every time 0.1, 0.2....\nprint('time elapsed:', end - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accu = history.history['accuracy']\nval_accu = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accu))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot(epochs, accu, 'bo-', label = 'Training acc')\nplot(epochs, val_accu, 'r*-', label = 'Validation acc')\nlegend()\ngrid()\nshow()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot(epochs, loss, 'bo-', label = 'Training loss')\nplot(epochs, val_loss, 'r*-', label = 'Validation loss')\nlegend()\ngrid()\nshow()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}